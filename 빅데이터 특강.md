# 빅데이터 및 프로젝트 특강



### 4차 산업혁명의 전반적 부분

- 4th 라는 단어를 가장 먼저 쓰고 책을 쓴 사람-Klaus Schwab회장
- 4차 산업혁명은 지능정보기술로 AI(지능)와 정보(빅데이터,IoT,클라우드)의 결합
- Ray Kuzwell,, 특이점이 온다 라는 책을 쓰고 미래를 예측한 
- 구성요소 : Connectivity + Inteligence
- IoT? no ===> IoEverything
- Google, Alpahbet 의 DeepMind 인수 - AI 의 발달



---



### Big Data

- Gartner,Inc : 3V정의, Volume, Velocity, Variety

- IBM : 4V, +Veracity(진실성)

- Brian Hopkins : +Variability(가변성)

- DDD : Data-Driven Decision Making, 데이터 주도 의사결정

  - DDD1 : 데이터 안에서 찾아야 하는 결정사항
  - DDD2 : 대규모로 반복되어 데이터 분석에 기반한 의사결정의 정확도가 약간만 향상되어도 큰 이득을 주는 결정사항

- **예측모델**은 객관성이 꼭!! 객관성이 있어야 한다. 그 객관성은 **수학**으로 확보

- 자동화 가능한 부분과 **창의력**이 요구되는 부분으로 나뉜다. 경험이 곧 창의력이 될수도!

- 통계의 회귀분석(Regression)과 다르게 예측의 분류모델은 Yes or No의 답이 주로 나온다.

- #### Data Mining Algorithms

  1. 분류와 계층확률 추정 (Classification & Class Probability Estimation)

     -각 개인이 어느 계층에 속할 것인지 예측, 각 계층은 상호 배타적

  2. 회귀분석 (Regression) - 어떤일이 얼마나 많이 일어나는 지 예측

  3. 유사도 매칭 (Similarity Matching) - 데이터에 기반해 비슷한 개인을 찾음, 제품추천

  4. 군집화 (Clustering) - 목적 없는 상태에서 유사도에 따라 개인을 묶음

  5. 동시발생 그룹화 (Co-occurrence Group) - 장바구니, 어떤 상품을 함께 구매?

  6. 프로파일링 (Profiling) - 행위기술

  7. 연결예측 (Link Prediction) - 연결 강도 추정해 데이터간 연결 예측, 추천시스템

  8. 데이터 축소 (Data Reduction) - 수학, 데이터의 feature 줄임, 정보 손실 but 통찰력 up

  9. 인과 모델링 (Causal Modeling) - 올바른 가정이 필요, 어떤 행위가 다른 행위에 영향



---



### Algorithm

- 예측 모델링
  1. 감독 세분화 (Supervised Segmentation)
     - Target Value 존재, Data를 세분화 할 것이다.
  2. 속성(Attribute) 찾기 : 데이터로 표현되는 객체의 정보를 전달하는 중요한 변수
- 예측 모델링 기법
  1. 엔트로피 (Entropy)
  2. 의사 결정 나무 (Decision Tree)
- 모델 : 어떤 목적 달성을 위해 실 세계를 단순하게 표현한 것..관련 없는 정보는 생략



---



#### 엔트로피(Entropy)

- 어떤 집합에 대한 무질서 정도를 측정

- Equation

  ```
  entropy = -(p1 log(p1)+p2 log(p2)+ . . . . . . . . . . )
    (여기서 p = 확률, probability)
  ```

- **엔트로피 그래프**(중요!! 머리에 이미지 그리며 생각하기)

  ![data entropy graph에 대한 이미지 검색결과](https://miro.medium.com/max/565/1*M15RZMSk8nGEyOnD8haF-A.png)

  - +와 -의 값이 동일하여 1에 가까울 수록 stable 한 상태
  - stable 하면 분류가 잘 되지 않는다
  - **빅데이터에서는 0에 가까울 수록 분류가 잘된 것!**

- 엔트로피 구할 때 공학 계산기를 사용하는데 log2 란게 없다..

  따라서 공식을 사용! if, **log2 0.7 =  log 0.7/log 2**

- 정보 증가량(Information Gain),IG

  ```
  IG(parents, children) 
  	= entropy(parents) - [p(c1)*entropy(c1)+p(c2)*entropy(c2)]
  					 (여기서 확률p 곱해주는 이유는? 웨이트,즉 가중치 주기위함)
  ```

  **IG의 숫자가 클수록 영향력이 있다**

- ##### Flow

  1. IG 의 영향력을 찾고싶다?

  2. 엔트로피를 구해야한다.

  3. 확률이 있어야 한다.

  4. 즉, 셀 수 있는 데이터를 갖고 있어야 한다.

     또한 셀 수 있게끔 **구간화**시켜야 한다.

     

---



#### 의사결정나무 (Decision Tree)

- Target Value를 봤을 때 모두 같은 값이면 알고리즘 STOP! 아니면 Segmentation  시작
- 각 Predictors 의 IG 를 계산해서 가장 영햑력이 큰 루트노드 선택(IG 높을수록 좋다)
- 만약 Target Value가 모두 같은 속성이 있으면 STOP = Leaf knod
- 최종 모델 생성 후 이를 if-else 절로 만들 수 있다. (큰 장점)